Postgres to AWS Aurora for Postgres Migration
==============================================================================
Keywords:


Overview
------------------------------------------------------------------------------
由于关系数据库在企业业务中的重要性, 关系数据库迁徙上云是企业上云中非常重要, 甚至是最为重要的一环. 本文以从自建机房的 Postgres 迁徙到 AWS Aurora for Postgres 为例, 介绍了迁徙的具体执行过程.


Core Component
------------------------------------------------------------------------------
在迁徙过程中我们使用的核心技术是 `AWS DMS <https://aws.amazon.com/dms/>`_. Database Migration Service), 只需要点击几下鼠标, 该服务就能帮我们创建一台专门用于迁徙的 EC2, 将源数据. Source DB) 中的所有数据以近实时的方式同步到. Target DB) 中. 当然, 任何数据同步方案都是有延迟的, 在实际操作过程中我们都必须要经历 "切断写流量, 并等待所有数据全部同步到 Target DB" -> "将读流量切换到 Target DB" -> "将写流量切换到 Target DB 并恢复写流量" 这一步骤. 该流程能确保我们凡是在写流量收到写入成功之后读到的数据都是最新的, 在逻辑上没有错误.


Migration Execution Plan
------------------------------------------------------------------------------
本节我们用图的方式来展示迁徙的执行过程.

.. raw:: html
    :file: ./Postgres-to-AWS-Aurora-for-Postgres-Migration.drawio.html


Additional Reading - Data Replication Technology
------------------------------------------------------------------------------
市面上大多数的数据库同步方案的本质其实是将用于迁徙的机器 "假扮" 成一个 Replica 节点, 这样主写入节点就会自动将 WAL. Write Ahead Log) 同步给用于迁徙的机器, 于是就可以做进一步的数据处理和数据复制了. AWS DMS 也不例外, 只不过 DMS 的核心是一套软件, 里面实现了如何将自己注册为 Replica 节点的逻辑, 如何处理数据的逻辑, 以及如何将数据写入到 Target DB 的逻辑. 这些细节是相当复杂且工作量巨大的. 跟市场上很多开源工具箱比, DMS 的价值主要是让用于迁徙的机器的部署和配置工作都自动化了, 从而大大降低了迁徙的复杂度.


Additional Reading - Considerations in Database Migration
------------------------------------------------------------------------------
**为什么要进行数据库迁徙?**

    **从需求角度来讲**

    1. 应用软件需求侧：兼容性, 如SAP软件, ORACLE EBS软件对数据库的版本, 组件的要求. 
    2. 合规需求：法务合规等, 对软件正版化的需求. 
    3. 安全需求：新的版本, 解决安全或BUG漏洞. 定期的补丁更新, BUG漏洞修复, 安全修复等. 
    4. 成本考虑, 如迁移到云环境, 从云环境迁移到本地自建机房等. 从AIX迁移到LINUX等. 
    5. 性能需求, 从差的设备迁移到更好的设备; 从一种数据库迁移到具有更好性能, 特性的数据库等. 
    6. 高可用等需求：迁移到具备高可用, 集群的环境. 

    **从运维管理角度**

    1. 存储硬件更换：需要将数据迁移到新存储. 
    2. 服务器硬件更换：新的硬件平台, 使用新的架构, 新的操作系统版本等, 需要配套新的数据库版本, 需要进行升级迁移. 
    3. 机房搬迁等.

**数据库迁移前应该做哪些方面的评估工作?**

    **迁移的支持角色评估** - 多方协调工作

    使用方的It维护人员, 应用系统管理人员, 应用系统的供应商, 硬件基础平台的集成供应商（包括存储, 网络, 服务器, 操作系统) , 业务依赖的中间件厂商（类似像 weblogic, webshpere, tomcat, 或者是网络安全, 数据安全设备厂商, 或者是类似 Goldengate, Dsg 等之类的数据抽取复制供应商), 迁移厂商, 他们之间的多方协调工作.

    **硬件资源评估** - 应用系统以及数据库生命周期

    基本围绕五个维度: 网络带宽, 内存, CPU, 数据容及IO吞吐量, 备份. 

    **迁移方式与时间的评估** - 合理的迁移技术选择

    数据迁移有多种技术手段, 首先还是要考虑场景. 

    1. 是否不同数据库之间的迁移
    2. 还是同数据库之间的迁移
    3. 又或是同数据库不同版本之间的迁移, 是升版本还是降版本
    4. 是否需要升级. 

    其次才是考虑选择迁移技术. 

    用冷拷贝, 自带的备份恢复工具, 数据逻辑复制, 数据物理复制甚至像低代码平台的数据抽取功能等等有非常多的选择, 场景不同可以选择的方式也不同, 找到适合当前场景的就需要作出合适的判断, 而判断的指标我总结为几个方面如下：

    1. 是否有停机时间, 就是指的停机时间窗口, 在线迁移以及离线迁移是两回事, 这个分水岭直接关系到迁移的技术选择; 
    2. 停机时间窗口多久, 不同的迁移技术选择所花费的时间也是不一样的; 
    3. 首要考虑熟悉的技术, 工程师技术掌握个与所长, 扬长避短, 不做没把握的事情; 
    4. 数据校验时间; 
    5. 对性能影响的考虑, 比如 Oracle 的 expdp 方式, 其实迁移后你不做统计信息收集, 对性能影像还是很大, 或者涉及到大升级, 就需要把调优的工作在迁移完成之前就需要尽可能的测试完成.

    **迁移性能评估** - 评估高地

    对数据库性能的了解是非常有必要的一个工作, 迁移之后的性能也是关系着数据迁移成败, 主要

    难点一, 是在于不同数据库之间的迁移后, 性能波动情况的了解. 同数据库之间相比而言比较容易判断.

    难点二, 是对数据库未来运行的性能趋势评估, 这个会比较紧密结合前面提到的硬件资源评估, 数据增量, CPU开销增长, 带宽增长. 所以一般可以看到很多厂商在做硬件资源评估时候喜欢往顶里报, 但客户往往会从成本考虑, 我也建议我的同事在做迁移工作时候, 利用已有的运维平台数据, 结合硬件需求, 对未来的性能做一个规划. 白鳝之前分享过容量规划的概念, 其实跟我表达的意思基本一致. 在该部分有一个好的工具会节约大量的时间. 

    **迁移的兼容性评估** - 目标版本, 补丁, 系统, 配置

    兼容性方面, 无论迁移过程是跨类型, 跨平台, 升级, 降级主要涉及到几个方面：

    1. 数据库本身的附带功能（监听, Dlink) , 函数, 数据类型, 非标SQL的支持等; 
    2. 应用程序的兼容, 是否适配过相关数据库的版本获得过厂家的认证支持; 
    3. 中间件的兼容, 我碰到过主要的中间件兼容问题就是在金融领域texudo的兼容问题, 现在数据库版本迭代快, 而texudo或者像weblogic这类中间件老版本上经常会出现不兼容的情况, 这一类需要在准备工作中做足测试; 
    4. 操作系统的兼容, 比如主流的操作系统版本选择, 相关补丁. 目前信创如火如荼, 国产的操作系统方面对相关数据库版本的支持需要做充足的准备工作; 
    5. 硬件兼容性, 主要体现在驱动层面. 

    **迁移的回退工作评估** - 能进能退方成大全

    这是个有意思的地方, 回退往往意味着迁移失败, 原因也是多方面的, 可能是数据出问题, 性能出问题, 超出停机允许时间, 兼容问题等等, 好在大部分的迁移都是离线迁移, 所以回退其实是个简单的工作, 只需要将业务恢复原状即可. 在一些项目中特别是在线热迁移的情况下, 甚至其实客户本身意识到没有回退可能了, 但我们还是习惯会去考虑, 真的没有办法回退了么? 比如Oracle在线跨版本热迁移, 主要面临的问题就是迁移后数据变动了, 但是发现需要回退, 这个时候怎么办? 有没有办法规避这类问题. 

Reference:

- `数据库迁移如何优化方案和避坑? <https://zhuanlan.zhihu.com/p/598515532>`_
